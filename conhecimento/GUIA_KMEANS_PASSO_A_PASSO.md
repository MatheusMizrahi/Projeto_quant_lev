# ğŸ“ Guia Completo: K-Means para AnÃ¡lise de Intensidade de Regimes

## ğŸ“š Ãndice
1. [VisÃ£o Macro do Processo](#visÃ£o-macro)
2. [Teoria do K-Means](#teoria)
3. [ImplementaÃ§Ã£o Passo a Passo](#implementaÃ§Ã£o)
4. [AplicaÃ§Ã£o ao Projeto](#aplicaÃ§Ã£o)

---

## ğŸ—ºï¸ VisÃ£o Macro do Processo {#visÃ£o-macro}

### **Fluxo Completo da Fase 4:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FASE 4: K-MEANS                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ENTRADA                    PROCESSAMENTO                 SAÃDA
â”€â”€â”€â”€â”€â”€â”€                    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                 â”€â”€â”€â”€â”€

ğŸ“Š HistÃ³rico de     â†’  1ï¸âƒ£ Preparar Features      â†’  ğŸ“ˆ Features
   Quadrantes              (magnitude, vol, etc)        Normalizadas
   (CSV)                                                
                                                         
                       2ï¸âƒ£ Encontrar K Ã“timo      â†’  ğŸ“Š GrÃ¡ficos
                          (Elbow + Silhouette)          de ValidaÃ§Ã£o
                                                         
                       3ï¸âƒ£ Treinar K-Means        â†’  ğŸ¤– Modelo
                          (clustering)                   Treinado
                                                         
                       4ï¸âƒ£ Mapear Intensidades    â†’  ğŸ·ï¸ Labels
                          (Fraco/Moderado/Forte)         SemÃ¢nticos
                                                         
                       5ï¸âƒ£ Classificar Atual      â†’  âœ… Regime +
                          (predict)                      Intensidade
```

### **Analogia DidÃ¡tica:**

Imagine que vocÃª tem **centenas de fotos de tempestades** e quer classificÃ¡-las automaticamente em:
- ğŸŸ¢ **Chuva Leve** (fraca)
- ğŸŸ¡ **Temporal** (moderado)  
- ğŸ”´ **FuracÃ£o** (forte)

**Problema:** VocÃª nÃ£o sabe qual foto Ã© qual categoria.

**SoluÃ§Ã£o K-Means:** 
1. O algoritmo analisa **caracterÃ­sticas** de cada foto (velocidade do vento, volume de chuva, nuvens)
2. Agrupa fotos **similares** automaticamente
3. VocÃª rotula cada grupo depois (ex: "Grupo 1 = Chuva Leve")

**No nosso caso:**
- Fotos = Dias de anÃ¡lise histÃ³rica
- CaracterÃ­sticas = InflaÃ§Ã£o, Atividade, Volatilidade
- Grupos = Fraco, Moderado, Forte

---

## ğŸ§  Teoria do K-Means {#teoria}

### **O que Ã© Clustering?**

**Clustering** Ã© agrupar dados **similares** sem ter rÃ³tulos prÃ©vios (aprendizado nÃ£o-supervisionado).

**Exemplo Visual:**

```
Antes do K-Means (sÃ³ pontos):        Depois do K-Means (3 clusters):

    â€¢     â€¢  â€¢                            ğŸ”´     ğŸ”´  ğŸ”´
  â€¢   â€¢      â€¢                          ğŸ”´   ğŸ”´      ğŸ”´
       â€¢  â€¢                                  ğŸ”´  ğŸ”´
                                      
    â€¢    â€¢                                ğŸŸ¡    ğŸŸ¡
  â€¢  â€¢     â€¢                            ğŸŸ¡  ğŸŸ¡     ğŸŸ¡
                                      
      â€¢  â€¢   â€¢                              ğŸ”µ  ğŸ”µ   ğŸ”µ
    â€¢      â€¢                              ğŸ”µ      ğŸ”µ
```

---

### **Como Funciona o K-Means?**

#### **Passo 1: Escolher K (nÃºmero de clusters)**
```
K = 3  â†’  Queremos 3 grupos (Fraco, Moderado, Forte)
```

#### **Passo 2: Inicializar CentrÃ³ides AleatÃ³rios**
```
CentrÃ³ide = ponto central de um cluster

Exemplo em 2D (InflaÃ§Ã£o Ã— Atividade):

  Atividade â†‘
      |
    3 |     C1 â—
      |              
    2 |          C2 â—
      |
    1 |  C3 â—
      |
    0 +â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ InflaÃ§Ã£o
        0   1   2   3

C1, C2, C3 = centrÃ³ides iniciais (aleatÃ³rios)
```

#### **Passo 3: Atribuir Pontos ao CentrÃ³ide Mais PrÃ³ximo**
```
Para cada ponto, calcular distÃ¢ncia euclidiana:

d = âˆš[(xâ‚ - xâ‚‚)Â² + (yâ‚ - yâ‚‚)Â²]

Exemplo:
Ponto A = (1.5, 2.5)
C1 = (2, 3)   â†’  d = âˆš[(1.5-2)Â² + (2.5-3)Â²] = 0.71
C2 = (3, 2)   â†’  d = âˆš[(1.5-3)Â² + (2.5-2)Â²] = 1.58
C3 = (1, 1)   â†’  d = âˆš[(1.5-1)Â² + (2.5-1)Â²] = 1.58

Resultado: Ponto A pertence a C1 (menor distÃ¢ncia)
```

#### **Passo 4: Recalcular CentrÃ³ides**
```
Novo centrÃ³ide = mÃ©dia de todos os pontos do cluster

Cluster C1: pontos (1, 2), (2, 3), (1.5, 2.5)
Novo C1 = ( (1+2+1.5)/3 , (2+3+2.5)/3 ) = (1.5, 2.5)
```

#### **Passo 5: Repetir atÃ© ConvergÃªncia**
```
CritÃ©rio de parada:
- CentrÃ³ides nÃ£o mudam mais, OU
- MÃ¡ximo de iteraÃ§Ãµes atingido (ex: 300)
```

---

### **MÃ©tricas de Qualidade do Clustering**

#### **1. InÃ©rcia (Within-Cluster Sum of Squares)**
```
InÃ©rcia = Soma das distÃ¢nciasÂ² de cada ponto ao seu centrÃ³ide

Quanto MENOR, melhor (pontos mais prÃ³ximos dos centros)

FÃ³rmula:
Î£ (distÃ¢ncia do ponto ao centrÃ³ide)Â²
```

#### **2. Silhouette Score (CoesÃ£o vs. SeparaÃ§Ã£o)**
```
Range: -1 a +1

+1 = Clusters muito bem separados
 0 = Clusters sobrepostos
-1 = Pontos no cluster errado

FÃ³rmula para cada ponto i:
s(i) = (b - a) / max(a, b)

Onde:
a = distÃ¢ncia mÃ©dia aos pontos do MESMO cluster
b = distÃ¢ncia mÃ©dia aos pontos do cluster MAIS PRÃ“XIMO
```

**Exemplo Visual:**
```
Silhouette = 0.8 (BOM)          Silhouette = 0.2 (RUIM)

  ğŸ”´ğŸ”´ğŸ”´                          ğŸ”´ğŸ”µğŸ”´
  ğŸ”´ğŸ”´ğŸ”´                          ğŸ”µğŸ”´ğŸ”µ
              ğŸ”µğŸ”µğŸ”µ               ğŸ”´ğŸ”µğŸ”µ
              ğŸ”µğŸ”µğŸ”µ               ğŸ”µğŸ”´ğŸ”´

Bem separados                   Misturados
```

---

### **Como Escolher K (NÃºmero de Clusters)?**

#### **MÃ©todo 1: Elbow Method (Cotovelo)**
```
Plotar InÃ©rcia vs. K

InÃ©rcia
   |
   |â•²
   | â•²
   |  â•²_____ â† "Cotovelo" (K Ã³timo)
   |      â”€â”€â”€â”€â”€â”€â”€
   +â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ K
      2  3  4  5  6

Escolher o ponto onde a curva "dobra"
```

#### **MÃ©todo 2: Silhouette Score**
```
Plotar Silhouette vs. K

Score
   |      â—
   |    â—   â—
   |  â—       â—
   |â—           â—
   +â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ K
      2  3  4  5  6

Escolher o K com MAIOR score
```

---

## ğŸ’» ImplementaÃ§Ã£o Passo a Passo {#implementaÃ§Ã£o}

### **PASSO 1: Carregar Dados HistÃ³ricos**

#### **Teoria:**
Precisamos de um histÃ³rico de observaÃ§Ãµes passadas para o K-Means "aprender" os padrÃµes.

#### **CÃ³digo:**
```python
import pandas as pd
import numpy as np

# Carregar histÃ³rico de quadrantes (gerado pela anÃ¡lise_historica.py)
df_historico = pd.read_csv('historico_quadrantes.csv', parse_dates=['data'])

print(f"âœ“ Carregado: {len(df_historico)} observaÃ§Ãµes histÃ³ricas")
print(f"âœ“ PerÃ­odo: {df_historico['data'].min()} a {df_historico['data'].max()}")
print("\nColunas disponÃ­veis:")
print(df_historico.columns.tolist())
```

**Exemplo de Output:**
```
âœ“ Carregado: 245 observaÃ§Ãµes histÃ³ricas
âœ“ PerÃ­odo: 2020-03-15 a 2025-11-20
Colunas disponÃ­veis:
['data', 'quadrante', 'inflacao_score', 'atividade_score']
```

#### **O que esperar:**
DataFrame com estrutura:
```
     data        quadrante            inflacao_score  atividade_score
0    2020-03-15  Q3: ESTAGFLAÃ‡ÃƒO      0.45           -0.32
1    2020-03-20  Q3: ESTAGFLAÃ‡ÃƒO      0.52           -0.28
...
```

---

### **PASSO 2: Criar Features para Clustering**

#### **Teoria:**
Features = caracterÃ­sticas numÃ©ricas que o K-Means usarÃ¡ para agrupar.

**Por que nÃ£o usar apenas os scores?**
- Precisamos capturar **intensidade** e **estabilidade** do regime
- Scores sozinhos nÃ£o dizem se o sinal Ã© volÃ¡til ou consistente

**Features que vamos criar:**

| Feature | O que Mede | FÃ³rmula |
|---------|-----------|---------|
| **magnitude** | ForÃ§a total do sinal | âˆš(inflaÃ§Ã£oÂ² + atividadeÂ²) |
| **inflacao_abs** | DireÃ§Ã£o de inflaÃ§Ã£o | \|inflaÃ§Ã£o_score\| |
| **atividade_abs** | DireÃ§Ã£o de atividade | \|atividade_score\| |
| **inflacao_vol** | Instabilidade inflaÃ§Ã£o | std(Ãºltimos 20 dias) |
| **atividade_vol** | Instabilidade atividade | std(Ãºltimos 20 dias) |
| **consistencia** | Estabilidade quadrante | % dias no mesmo quadrante |

#### **CÃ³digo:**
```python
def preparar_features(df):
    """
    Cria features para K-Means.
    
    Args:
        df: DataFrame com colunas [inflacao_score, atividade_score, quadrante]
    
    Returns:
        DataFrame com 6 features normalizadas
    """
    features = pd.DataFrame()
    
    # Feature 1: Magnitude (distÃ¢ncia da origem)
    # Teoria: Quanto mais longe de (0,0), mais forte o sinal
    features['magnitude'] = np.sqrt(
        df['inflacao_score']**2 + 
        df['atividade_score']**2
    )
    
    # Feature 2 e 3: Valores absolutos
    # Teoria: Queremos intensidade independente da direÃ§Ã£o
    features['inflacao_abs'] = df['inflacao_score'].abs()
    features['atividade_abs'] = df['atividade_score'].abs()
    
    # Feature 4 e 5: Volatilidade (janela de 20 dias)
    # Teoria: Sinal volÃ¡til = menos confiÃ¡vel
    features['inflacao_vol'] = (
        df['inflacao_score']
        .rolling(window=20, min_periods=5)
        .std()
        .fillna(0)
    )
    features['atividade_vol'] = (
        df['atividade_score']
        .rolling(window=20, min_periods=5)
        .std()
        .fillna(0)
    )
    
    # Feature 6: ConsistÃªncia do quadrante
    # Teoria: Se mudou de quadrante recentemente = sinal fraco
    def calcular_consistencia(serie):
        """Calcula % de dias no mesmo quadrante (Ãºltimos 20)"""
        if len(serie) < 5:
            return 0.5  # Valor neutro
        return (serie == serie.iloc[-1]).sum() / len(serie)
    
    features['consistencia'] = (
        df['quadrante']
        .rolling(window=20, min_periods=5)
        .apply(calcular_consistencia)
        .fillna(0.5)
    )
    
    return features

# Aplicar
features = preparar_features(df_historico)
print("\nâœ“ Features criadas:")
print(features.describe())
```

**Exemplo de Output:**
```
âœ“ Features criadas:
         magnitude  inflacao_abs  atividade_abs  inflacao_vol  atividade_vol  consistencia
count    245.00      245.00        245.00         245.00        245.00         245.00
mean     0.52        0.31          0.35           0.08          0.06           0.72
std      0.23        0.18          0.19           0.04          0.03           0.21
min      0.05        0.01          0.02           0.00          0.00           0.20
max      1.15        0.78          0.82           0.25          0.18           1.00
```

**InterpretaÃ§Ã£o:**
- Magnitude mÃ©dia = 0.52 â†’ Sinal moderado
- ConsistÃªncia mÃ©dia = 72% â†’ Regime costuma ser estÃ¡vel

---

### **PASSO 3: Normalizar Features (PadronizaÃ§Ã£o)**

#### **Teoria:**
K-Means usa **distÃ¢ncia euclidiana**, que Ã© sensÃ­vel Ã  escala.

**Problema sem normalizaÃ§Ã£o:**
```
Feature A: magnitude = 0.8    (range 0-1)
Feature B: volatilidade = 150  (range 0-500)

DistÃ¢ncia serÃ¡ dominada por Feature B!
```

**SoluÃ§Ã£o: StandardScaler**
```
FÃ³rmula: z = (x - Î¼) / Ïƒ

Onde:
x = valor original
Î¼ = mÃ©dia
Ïƒ = desvio padrÃ£o

Resultado: todos os valores com mÃ©dia=0 e std=1
```

#### **CÃ³digo:**
```python
from sklearn.preprocessing import StandardScaler

def normalizar_features(features):
    """
    Normaliza features usando StandardScaler.
    
    Teoria: Transforma cada coluna para mÃ©dia=0 e std=1
    
    Returns:
        features_scaled: array numpy normalizado
        scaler: objeto para normalizar novos dados
    """
    scaler = StandardScaler()
    features_scaled = scaler.fit_transform(features)
    
    print("\nâœ“ Features normalizadas:")
    print(f"   Shape: {features_scaled.shape}")
    print(f"   MÃ©dia: {features_scaled.mean(axis=0).round(3)}")
    print(f"   Std: {features_scaled.std(axis=0).round(3)}")
    
    return features_scaled, scaler

# Aplicar
features_scaled, scaler = normalizar_features(features)
```

**Exemplo de Output:**
```
âœ“ Features normalizadas:
   Shape: (245, 6)
   MÃ©dia: [0. 0. 0. 0. 0. 0.]  â† Todas prÃ³ximas de 0
   Std: [1. 1. 1. 1. 1. 1.]    â† Todas = 1
```

---

### **PASSO 4: Encontrar K Ã“timo (Elbow + Silhouette)**

#### **Teoria:**
Testar diferentes valores de K (2 a 8) e escolher o melhor.

**CritÃ©rios:**
1. **Elbow**: Onde a inÃ©rcia para de cair muito
2. **Silhouette**: Onde o score Ã© mÃ¡ximo

#### **CÃ³digo:**
```python
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt

def encontrar_k_otimo(features_scaled, max_k=8):
    """
    Testa K de 2 atÃ© max_k e plota mÃ©tricas.
    
    Returns:
        DataFrame com resultados
    """
    resultados = {'K': [], 'Inertia': [], 'Silhouette': []}
    
    for k in range(2, max_k + 1):
        print(f"Testando K={k}...", end=' ')
        
        # Treinar K-Means
        kmeans = KMeans(
            n_clusters=k,
            random_state=42,  # Seed para reprodutibilidade
            n_init=10,        # 10 inicializaÃ§Ãµes diferentes
            max_iter=300      # MÃ¡ximo de iteraÃ§Ãµes
        )
        labels = kmeans.fit_predict(features_scaled)
        
        # Calcular mÃ©tricas
        inertia = kmeans.inertia_
        silhouette = silhouette_score(features_scaled, labels)
        
        resultados['K'].append(k)
        resultados['Inertia'].append(inertia)
        resultados['Silhouette'].append(silhouette)
        
        print(f"Inertia={inertia:.2f}, Silhouette={silhouette:.3f}")
    
    df_resultados = pd.DataFrame(resultados)
    
    # Plotar grÃ¡ficos
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))
    
    # Elbow Method
    ax1.plot(df_resultados['K'], df_resultados['Inertia'], 'bo-', linewidth=2, markersize=8)
    ax1.set_xlabel('NÃºmero de Clusters (K)', fontsize=12)
    ax1.set_ylabel('InÃ©rcia (WCSS)', fontsize=12)
    ax1.set_title('Elbow Method', fontsize=14, fontweight='bold')
    ax1.grid(True, alpha=0.3)
    
    # Silhouette Score
    ax2.plot(df_resultados['K'], df_resultados['Silhouette'], 'ro-', linewidth=2, markersize=8)
    ax2.set_xlabel('NÃºmero de Clusters (K)', fontsize=12)
    ax2.set_ylabel('Silhouette Score', fontsize=12)
    ax2.set_title('Silhouette Analysis', fontsize=14, fontweight='bold')
    ax2.grid(True, alpha=0.3)
    ax2.axhline(y=0, color='black', linestyle='--', alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('k_otimo_analise.png', dpi=300)
    print("\nâœ“ GrÃ¡ficos salvos em 'k_otimo_analise.png'")
    plt.show()
    
    return df_resultados

# Executar
df_k_otimo = encontrar_k_otimo(features_scaled, max_k=6)
print("\nğŸ“Š Resultados:")
print(df_k_otimo)
```

**Exemplo de Output:**
```
Testando K=2... Inertia=1245.32, Silhouette=0.421
Testando K=3... Inertia=845.67, Silhouette=0.487
Testando K=4... Inertia=623.45, Silhouette=0.452
Testando K=5... Inertia=512.34, Silhouette=0.398
Testando K=6... Inertia=445.23, Silhouette=0.356

âœ“ GrÃ¡ficos salvos em 'k_otimo_analise.png'

ğŸ“Š Resultados:
   K    Inertia  Silhouette
0  2    1245.32      0.421
1  3     845.67      0.487  â† Melhor Silhouette
2  4     623.45      0.452
3  5     512.34      0.398
4  6     445.23      0.356
```

**InterpretaÃ§Ã£o:**
- **K=3** tem o melhor Silhouette (0.487)
- Cotovelo estÃ¡ entre K=3 e K=4
- âœ… **Escolha: K=3** (Fraco, Moderado, Forte)

---

### **PASSO 5: Treinar K-Means Final**

#### **CÃ³digo:**
```python
def treinar_kmeans_final(features_scaled, k=3):
    """
    Treina modelo final com K escolhido.
    
    Returns:
        kmeans: modelo treinado
        labels: rÃ³tulos de cluster para cada observaÃ§Ã£o
    """
    print(f"\nğŸ¤– Treinando K-Means com K={k}...")
    
    kmeans = KMeans(
        n_clusters=k,
        random_state=42,
        n_init=10,
        max_iter=300
    )
    
    labels = kmeans.fit_predict(features_scaled)
    
    # MÃ©tricas finais
    silhouette = silhouette_score(features_scaled, labels)
    
    print(f"âœ“ Modelo treinado!")
    print(f"âœ“ Silhouette Score: {silhouette:.3f}")
    print(f"âœ“ CentrÃ³ides salvos: {kmeans.cluster_centers_.shape}")
    print(f"\nğŸ“Š DistribuiÃ§Ã£o dos clusters:")
    unique, counts = np.unique(labels, return_counts=True)
    for cluster, count in zip(unique, counts):
        pct = (count / len(labels)) * 100
        print(f"   Cluster {cluster}: {count:3} observaÃ§Ãµes ({pct:5.1f}%)")
    
    return kmeans, labels

# Treinar
kmeans_final, labels = treinar_kmeans_final(features_scaled, k=3)
```

**Exemplo de Output:**
```
ğŸ¤– Treinando K-Means com K=3...
âœ“ Modelo treinado!
âœ“ Silhouette Score: 0.487
âœ“ CentrÃ³ides salvos: (3, 6)

ğŸ“Š DistribuiÃ§Ã£o dos clusters:
   Cluster 0:  89 observaÃ§Ãµes ( 36.3%)
   Cluster 1: 102 observaÃ§Ãµes ( 41.6%)
   Cluster 2:  54 observaÃ§Ãµes ( 22.0%)
```

---

### **PASSO 6: Mapear Clusters para Intensidades**

#### **Teoria:**
Os clusters sÃ£o apenas nÃºmeros (0, 1, 2). Precisamos interpretÃ¡-los como "Fraco/Moderado/Forte".

**LÃ³gica:**
- Cluster com **menor magnitude mÃ©dia** = Fraco
- Cluster com **magnitude intermediÃ¡ria** = Moderado  
- Cluster com **maior magnitude mÃ©dia** = Forte

#### **CÃ³digo:**
```python
def mapear_intensidades(features, labels):
    """
    Mapeia clusters numÃ©ricos para rÃ³tulos semÃ¢nticos.
    
    LÃ³gica: Cluster com maior magnitude = Forte
    
    Returns:
        dict: mapeamento {cluster: intensidade}
    """
    print("\nğŸ·ï¸ Mapeando clusters para intensidades...")
    
    # Adicionar labels Ã s features
    df_temp = features.copy()
    df_temp['cluster'] = labels
    
    # Calcular magnitude mÃ©dia por cluster
    magnitude_media = df_temp.groupby('cluster')['magnitude'].mean()
    print("\nğŸ“Š Magnitude mÃ©dia por cluster:")
    print(magnitude_media.sort_values())
    
    # Ordenar clusters por magnitude (menor â†’ maior)
    clusters_ordenados = magnitude_media.sort_values().index.tolist()
    
    # Criar mapeamento
    intensidades = ['Fraco', 'Moderado', 'Forte']
    mapeamento = {}
    
    for i, cluster in enumerate(clusters_ordenados):
        mapeamento[cluster] = intensidades[i]
        mag = magnitude_media[cluster]
        print(f"   Cluster {cluster} (mag={mag:.3f}) â†’ {intensidades[i]}")
    
    return mapeamento

# Aplicar
mapeamento = mapear_intensidades(features, labels)
```

**Exemplo de Output:**
```
ğŸ·ï¸ Mapeando clusters para intensidades...

ğŸ“Š Magnitude mÃ©dia por cluster:
cluster
0    0.28
1    0.52
2    0.85

   Cluster 0 (mag=0.283) â†’ Fraco
   Cluster 1 (mag=0.524) â†’ Moderado
   Cluster 2 (mag=0.847) â†’ Forte
```

---

### **PASSO 7: Adicionar Intensidades ao HistÃ³rico**

#### **CÃ³digo:**
```python
def adicionar_intensidades(df_historico, labels, mapeamento):
    """
    Adiciona colunas de cluster e intensidade ao histÃ³rico.
    """
    df_resultado = df_historico.copy()
    df_resultado['cluster'] = labels
    df_resultado['intensidade'] = [mapeamento[c] for c in labels]
    
    print("\nâœ… Intensidades adicionadas ao histÃ³rico!")
    print("\nğŸ“Š DistribuiÃ§Ã£o Final:")
    dist = df_resultado['intensidade'].value_counts()
    for intensidade, count in dist.items():
        pct = (count / len(df_resultado)) * 100
        print(f"   {intensidade:10} {count:3} perÃ­odos ({pct:5.1f}%)")
    
    return df_resultado

# Aplicar
df_final = adicionar_intensidades(df_historico, labels, mapeamento)

# Salvar
df_final.to_csv('historico_com_intensidade.csv', index=False)
print("\nâœ“ Resultados salvos em 'historico_com_intensidade.csv'")
```

**Exemplo de Output:**
```
âœ… Intensidades adicionadas ao histÃ³rico!

ğŸ“Š DistribuiÃ§Ã£o Final:
   Moderado    102 perÃ­odos ( 41.6%)
   Fraco        89 perÃ­odos ( 36.3%)
   Forte        54 perÃ­odos ( 22.0%)

âœ“ Resultados salvos em 'historico_com_intensidade.csv'
```

---

### **PASSO 8: Classificar ObservaÃ§Ã£o Atual**

#### **Teoria:**
Agora que temos o modelo treinado, podemos classificar **novos** dados.

#### **CÃ³digo:**
```python
def classificar_atual(inflacao_score, atividade_score, features_contexto, 
                      scaler, kmeans, mapeamento):
    """
    Classifica intensidade de uma nova observaÃ§Ã£o.
    
    Args:
        inflacao_score: score atual de inflaÃ§Ã£o
        atividade_score: score atual de atividade
        features_contexto: dict com volatilidades e consistÃªncia
        scaler: StandardScaler treinado
        kmeans: modelo K-Means treinado
        mapeamento: dict cluster â†’ intensidade
    
    Returns:
        dict com classificaÃ§Ã£o completa
    """
    # 1. Criar features
    features_atual = {
        'magnitude': np.sqrt(inflacao_score**2 + atividade_score**2),
        'inflacao_abs': abs(inflacao_score),
        'atividade_abs': abs(atividade_score),
        'inflacao_vol': features_contexto.get('inflacao_vol', 0.05),
        'atividade_vol': features_contexto.get('atividade_vol', 0.05),
        'consistencia': features_contexto.get('consistencia', 0.7)
    }
    
    # 2. Converter para array (mesma ordem do treinamento!)
    X = np.array([list(features_atual.values())])
    
    # 3. Normalizar (usar mesmo scaler do treinamento)
    X_scaled = scaler.transform(X)
    
    # 4. Prever cluster
    cluster = kmeans.predict(X_scaled)[0]
    
    # 5. Mapear para intensidade
    intensidade = mapeamento[cluster]
    
    # 6. Calcular distÃ¢ncia ao centrÃ³ide (confianÃ§a)
    distancia = np.linalg.norm(X_scaled - kmeans.cluster_centers_[cluster])
    
    resultado = {
        'intensidade': intensidade,
        'cluster': int(cluster),
        'magnitude': features_atual['magnitude'],
        'distancia_centroide': distancia,
        'features': features_atual
    }
    
    return resultado

# Exemplo de uso
# (Pegar Ãºltima observaÃ§Ã£o do histÃ³rico)
ultima = df_historico.iloc[-1]

resultado_atual = classificar_atual(
    inflacao_score=ultima['inflacao_score'],
    atividade_score=ultima['atividade_score'],
    features_contexto={
        'inflacao_vol': 0.06,
        'atividade_vol': 0.04,
        'consistencia': 0.8
    },
    scaler=scaler,
    kmeans=kmeans_final,
    mapeamento=mapeamento
)

print("\n" + "="*60)
print(" "*15 + "ğŸ¯ CLASSIFICAÃ‡ÃƒO ATUAL")
print("="*60)
print(f"\nğŸ“Š Regime: {ultima['quadrante']}")
print(f"ğŸ’ª Intensidade: {resultado_atual['intensidade']}")
print(f"ğŸ“ˆ Magnitude do Sinal: {resultado_atual['magnitude']:.3f}")
print(f"ğŸ¯ Cluster: {resultado_atual['cluster']}")
print(f"ğŸ“ DistÃ¢ncia ao CentrÃ³ide: {resultado_atual['distancia_centroide']:.3f}")
print("\nâœ… ClassificaÃ§Ã£o completa!")
print("="*60)
```

**Exemplo de Output:**
```
============================================================
               ğŸ¯ CLASSIFICAÃ‡ÃƒO ATUAL
============================================================

ğŸ“Š Regime: Q1: GOLDILOCKS
ğŸ’ª Intensidade: Forte
ğŸ“ˆ Magnitude do Sinal: 0.823
ğŸ¯ Cluster: 2
ğŸ“ DistÃ¢ncia ao CentrÃ³ide: 0.245

âœ… ClassificaÃ§Ã£o completa!
============================================================
```

---

## ğŸ¯ AplicaÃ§Ã£o ao Projeto {#aplicaÃ§Ã£o}

### **Arquivo Final: `Analise_intensidade.py`**

Agora vamos **integrar todos os passos** em uma classe reutilizÃ¡vel:

```python
"""
Analise_intensidade.py

Aplica K-Means para classificar intensidade dos regimes macroeconÃ´micos.
"""

import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt
from pathlib import Path


class AnalisadorIntensidade:
    """
    Classe completa para anÃ¡lise de intensidade via K-Means.
    """
    
    def __init__(self, n_clusters=3):
        self.n_clusters = n_clusters
        self.kmeans = None
        self.scaler = StandardScaler()
        self.mapeamento_intensidades = None
    
    def preparar_features(self, df):
        """PASSO 2: Criar features para clustering"""
        features = pd.DataFrame()
        
        features['magnitude'] = np.sqrt(
            df['inflacao_score']**2 + df['atividade_score']**2
        )
        features['inflacao_abs'] = df['inflacao_score'].abs()
        features['atividade_abs'] = df['atividade_score'].abs()
        
        features['inflacao_vol'] = (
            df['inflacao_score'].rolling(20, min_periods=5).std().fillna(0)
        )
        features['atividade_vol'] = (
            df['atividade_score'].rolling(20, min_periods=5).std().fillna(0)
        )
        
        def calc_consistencia(serie):
            if len(serie) < 5:
                return 0.5
            return (serie == serie.iloc[-1]).sum() / len(serie)
        
        features['consistencia'] = (
            df['quadrante'].rolling(20, min_periods=5)
            .apply(calc_consistencia).fillna(0.5)
        )
        
        return features
    
    def encontrar_k_otimo(self, features_scaled, max_k=6):
        """PASSO 4: Encontrar K Ã³timo"""
        resultados = {'K': [], 'Inertia': [], 'Silhouette': []}
        
        for k in range(2, max_k + 1):
            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
            labels = kmeans.fit_predict(features_scaled)
            
            resultados['K'].append(k)
            resultados['Inertia'].append(kmeans.inertia_)
            resultados['Silhouette'].append(silhouette_score(features_scaled, labels))
        
        return pd.DataFrame(resultados)
    
    def treinar(self, df_historico):
        """PASSOS 2, 3, 5, 6: Pipeline completo de treinamento"""
        print("\nğŸ”¬ Iniciando treinamento K-Means...\n")
        
        # Passo 2: Features
        print("1ï¸âƒ£ Preparando features...")
        features = self.preparar_features(df_historico)
        print(f"   âœ“ {len(features.columns)} features criadas")
        
        # Passo 3: Normalizar
        print("\n2ï¸âƒ£ Normalizando features...")
        features_scaled = self.scaler.fit_transform(features)
        print(f"   âœ“ Features padronizadas (mÃ©diaâ‰ˆ0, stdâ‰ˆ1)")
        
        # Passo 5: Treinar
        print(f"\n3ï¸âƒ£ Treinando K-Means (K={self.n_clusters})...")
        self.kmeans = KMeans(n_clusters=self.n_clusters, random_state=42, n_init=10)
        labels = self.kmeans.fit_predict(features_scaled)
        
        silhouette = silhouette_score(features_scaled, labels)
        print(f"   âœ“ Modelo treinado")
        print(f"   âœ“ Silhouette Score: {silhouette:.3f}")
        
        # Passo 6: Mapear intensidades
        print("\n4ï¸âƒ£ Mapeando intensidades...")
        self.mapeamento_intensidades = self._mapear(features, labels)
        
        print("\nâœ… Treinamento completo!\n")
        
        return labels, features
    
    def _mapear(self, features, labels):
        """PASSO 6: Mapear clusters â†’ intensidades"""
        df_temp = features.copy()
        df_temp['cluster'] = labels
        
        magnitude_media = df_temp.groupby('cluster')['magnitude'].mean()
        clusters_ordenados = magnitude_media.sort_values().index.tolist()
        
        intensidades = ['Fraco', 'Moderado', 'Forte']
        mapeamento = {}
        
        for i, cluster in enumerate(clusters_ordenados):
            mapeamento[cluster] = intensidades[i]
            print(f"   Cluster {cluster} â†’ {intensidades[i]}")
        
        return mapeamento
    
    def classificar(self, inflacao_score, atividade_score, features_contexto=None):
        """PASSO 8: Classificar nova observaÃ§Ã£o"""
        if self.kmeans is None:
            raise ValueError("Modelo nÃ£o treinado! Execute treinar() primeiro.")
        
        features_atual = {
            'magnitude': np.sqrt(inflacao_score**2 + atividade_score**2),
            'inflacao_abs': abs(inflacao_score),
            'atividade_abs': abs(atividade_score),
            'inflacao_vol': features_contexto.get('inflacao_vol', 0.05) if features_contexto else 0.05,
            'atividade_vol': features_contexto.get('atividade_vol', 0.05) if features_contexto else 0.05,
            'consistencia': features_contexto.get('consistencia', 0.7) if features_contexto else 0.7
        }
        
        X = np.array([list(features_atual.values())])
        X_scaled = self.scaler.transform(X)
        
        cluster = self.kmeans.predict(X_scaled)[0]
        intensidade = self.mapeamento_intensidades[cluster]
        
        return {
            'intensidade': intensidade,
            'cluster': int(cluster),
            'magnitude': features_atual['magnitude']
        }


# ============================================================================
# SCRIPT DE EXECUÃ‡ÃƒO
# ============================================================================

if __name__ == "__main__":
    # Carregar histÃ³rico
    df_historico = pd.read_csv('historico_quadrantes.csv', parse_dates=['data'])
    print(f"âœ“ Carregado: {len(df_historico)} observaÃ§Ãµes")
    
    # Criar analisador
    analisador = AnalisadorIntensidade(n_clusters=3)
    
    # Treinar
    labels, features = analisador.treinar(df_historico)
    
    # Adicionar ao histÃ³rico
    df_final = df_historico.copy()
    df_final['cluster'] = labels
    df_final['intensidade'] = [analisador.mapeamento_intensidades[c] for c in labels]
    
    # EstatÃ­sticas
    print("\nğŸ“Š DistribuiÃ§Ã£o de Intensidades:")
    dist = df_final['intensidade'].value_counts()
    for intensidade, count in dist.items():
        pct = (count / len(df_final)) * 100
        print(f"   {intensidade:10} {count:3} perÃ­odos ({pct:5.1f}%)")
    
    # Salvar
    df_final.to_csv('historico_com_intensidade.csv', index=False)
    print("\nâœ“ Resultados salvos em 'historico_com_intensidade.csv'")
    
    # Classificar observaÃ§Ã£o atual
    ultima = df_final.iloc[-1]
    resultado = analisador.classificar(
        ultima['inflacao_score'],
        ultima['atividade_score']
    )
    
    print("\n" + "="*60)
    print(" "*15 + "ğŸ¯ REGIME ATUAL")
    print("="*60)
    print(f"\nğŸ“Š Quadrante: {ultima['quadrante']}")
    print(f"ğŸ’ª Intensidade: {resultado['intensidade']}")
    print(f"ğŸ“ˆ Magnitude: {resultado['magnitude']:.3f}")
    print("="*60)
```

---

## ğŸ“š Resumo dos Conceitos

| Conceito | O que Ã© | Por que usar |
|----------|---------|--------------|
| **K-Means** | Algoritmo de clustering | Agrupa dados similares automaticamente |
| **CentrÃ³ide** | Centro de um cluster | Representa o "tÃ­pico" daquele grupo |
| **InÃ©rcia** | Soma das distÃ¢nciasÂ² aos centros | Mede compactaÃ§Ã£o dos clusters |
| **Silhouette** | CoesÃ£o vs. SeparaÃ§Ã£o | Valida qualidade dos clusters |
| **StandardScaler** | NormalizaÃ§Ã£o z-score | Iguala escalas das features |
| **Features** | CaracterÃ­sticas numÃ©ricas | Dados que o K-Means usa para agrupar |

---

## âœ… Checklist de ImplementaÃ§Ã£o

- [ ] **Passo 1**: Carregar histÃ³rico de quadrantes
- [ ] **Passo 2**: Criar 6 features (magnitude, abs, vol, consistÃªncia)
- [ ] **Passo 3**: Normalizar features com StandardScaler
- [ ] **Passo 4**: Testar K de 2 a 6 (Elbow + Silhouette)
- [ ] **Passo 5**: Treinar K-Means final (K=3)
- [ ] **Passo 6**: Mapear clusters â†’ Fraco/Moderado/Forte
- [ ] **Passo 7**: Adicionar intensidades ao histÃ³rico
- [ ] **Passo 8**: Classificar observaÃ§Ã£o atual
- [ ] **Passo 9**: Salvar resultados e visualizar

---

## ğŸ“ ExercÃ­cios PrÃ¡ticos

### **ExercÃ­cio 1: Entender Features**
Calcule manualmente as features para esta observaÃ§Ã£o:
```
inflacao_score = 0.6
atividade_score = -0.4
```

Resposta:
- magnitude = âˆš(0.6Â² + 0.4Â²) = âˆš0.52 = 0.72
- inflacao_abs = 0.6
- atividade_abs = 0.4

### **ExercÃ­cio 2: Interpretar Silhouette**
Se Silhouette = 0.15, os clusters estÃ£o bem separados?

Resposta: NÃ£o. 0.15 Ã© baixo (prÃ³ximo de 0), indicando sobreposiÃ§Ã£o.

### **ExercÃ­cio 3: Escolher K**
Dados:
```
K=2: Silhouette=0.35, Inertia=1200
K=3: Silhouette=0.52, Inertia=800
K=4: Silhouette=0.48, Inertia=650
```
Qual K escolher?

Resposta: K=3 (melhor Silhouette e cotovelo na inÃ©rcia)

---

## ğŸš€ PrÃ³ximos Passos

ApÃ³s dominar o K-Means:

1. **Fase 5**: Criar trading rules por quadrante + intensidade
2. **Fase 6**: Backtesting das estratÃ©gias
3. **Fase 7**: Dashboard de visualizaÃ§Ã£o
4. **Fase 8**: AutomaÃ§Ã£o e deploy

---

> **"Machine Learning nÃ£o Ã© mÃ¡gica. Ã‰ matemÃ¡tica bem aplicada."**  
> â€” LEV Quant Research Lab
